{
 "cells": [
  {
   "cell_type": "raw",
   "id": "007466aa",
   "metadata": {},
   "source": [
    "1. What is prior probability? Give an example."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2eddbe78",
   "metadata": {},
   "source": [
    "Prior probability shows the likelihood of an outcome in a given dataset.\n",
    "\n",
    "The goal is to draw inferences about an unknown variable X by observing a related random variable Y. The unknown variable is modeled as a random variable X, with prior distribution\n",
    "    \n",
    "\n",
    "The prior probability of a given target class is the propotion of its occurance compared with the other target state.\n",
    "Example: In the mortage case , P(Y) is the default rate on a home mortage "
   ]
  },
  {
   "cell_type": "raw",
   "id": "629be22a",
   "metadata": {},
   "source": [
    "2. What is posterior probability? Give an example."
   ]
  },
  {
   "cell_type": "raw",
   "id": "70a322d3",
   "metadata": {},
   "source": [
    "Posterior probability is revised probability that takes into account new available information.\n",
    "\n",
    "After observing the value of the random variable Y, we find the posterior distribution of X. This is the conditional PDF (or PMF) of X given Y=y,\n",
    "\n",
    "For example: let there be two urns, urnA having 5 black balls and 10 red ballsand urnB having 10black balls and 5 red balls.\n",
    "Now if an urn is select data random, the probability that urnA is choosen is 0.5. This is the prior probability.\n",
    "If we are given an additional piece of information that a ball was drawn at random from the selected urn and that ball was black then what is the probability that choosen urnA?\n",
    "Posterior probability takes into account this additional information and revises the probability downword from 0.5 0.33 according to bayes theorem because  a black is more probable from urnB than A."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f68132d",
   "metadata": {},
   "source": [
    "3. What is likelihood probability? Give an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89f1aab6",
   "metadata": {},
   "source": [
    "likelihood refers to how well a sample provides support for particular values of parameters in model.\n",
    "When we calculated likelihood we are trying to determine if we trust the parameters in a model based on the sample data that we observed.\n",
    "Example:\n",
    "     Now suppose the same coin is tossed 50 times and it shows heads only 14 times you would assume that the likelihood of the unbiased coin is very low , If the coin were fair it would have shown head and trails the same number of times."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c361d7d4",
   "metadata": {},
   "source": [
    "4. What is Naïve Bayes classifier? Why is it named so?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89748f6d",
   "metadata": {},
   "source": [
    "Naive Bayes classifier is one of the simple and most effective classification algorithm which helps in building the fast Ml algorithm that can make quik prediction.\n",
    "It is a probabilistic classifier, which means the predictions on the basis of the probability of an object .It is a classification technique based Bayesian theorem with an assumption of independence among predictors.\n",
    "The fundamental naive bayes assumption is that each feature makes an prediction and equal contribution to the outcome."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7123337",
   "metadata": {},
   "source": [
    "5. What is optimal Bayes classifier?\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edbbbaf8",
   "metadata": {},
   "source": [
    "Bayes optimal classifier is a probabilistic model that finds the most probable prediction  using the training data and space of hypothesis to make a prediction for a new data instance.\n",
    "This model is also reffered to as the bayes optimal learner , the bayes classifier , bayes optimal decision boundary.\n",
    "In general the most probable classification of new instances is obtained by combining the predictions of all hypothesis, weighed by their posterior probabilities.\n",
    "The most probable classification of the new instance is denoted by combining the predictions of all hypothesis, weighted by their posterior probabilities. If the possible class of new example can take on any value from some set V, The probability\n",
    "P(vj|D) that the correct classification for new instance Vj."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c351a24a",
   "metadata": {},
   "source": [
    "6. Write any two features of Bayesian learning methods."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5caf5937",
   "metadata": {},
   "source": [
    "1.each observed training example can incrementally decreases or increases the estimated probability that hypothesis is connected.\n",
    "2.This provides a more flexible approach to learning that algorithm that completely eliminate.A hypothesis if it is found to be inconsisent with any single example.\n",
    "3.Prior knowledge can be combined with observe data to determine final probability of a hypothesis.In bayseian learning prior knowledge is provided by asserting.\n",
    "4.Bayesian methods can accomadate hypothesis that make probabilistic predictions."
   ]
  },
  {
   "cell_type": "raw",
   "id": "723a10de",
   "metadata": {},
   "source": [
    "7. Define the concept of consistent learners."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ea54b99",
   "metadata": {},
   "source": [
    "A learner L using a hypothesis H and training data D is said to be consistent learner if it always outputs a hypothesis with zero error on D When ever H contains such as a hypothsis.\n",
    "By this, we can say   ,A consistent learner must produce a hypothesis in  the version space for H given D."
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc329454",
   "metadata": {},
   "source": [
    "8. Write any two strengths of Bayes classifier."
   ]
  },
  {
   "cell_type": "raw",
   "id": "698286f1",
   "metadata": {},
   "source": [
    "Althought the bayes optimal classifier obtains the best performance that can be achieved from the given training data , it can be qite costly to apply.\n",
    "The Expense is due to the fact that it comuptes the posterior probability for every hypothesis in H and then combines the predictions of each hypothesis to classify each new instance.\n",
    "ADVANTAGES:\n",
    "1.It provides a natural and principled way of combining prior information with adat , with in a solid decision theritical frame work.\n",
    "2.It provides inferences that are conditional on the data and are exact without reliance on asynptotic approximation.\n",
    "3.It observe the liklihood principle.It provides interpretable answers  and it provides a convinenet setting for a wide range of models.\n",
    "\n",
    "DISADVANTAGES:\n",
    "1.It does not tell you how too select a prior .There is no correct way to choose a prior.\n",
    "2.It can produce posterior distributions that rae haevily influenmced by the priors\n",
    "3.It often comes with a high computational cost ,especially in model with a large number of parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "756cca50",
   "metadata": {},
   "source": [
    "9. Write any two weaknesses of Bayes classifier."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d26063b6",
   "metadata": {},
   "source": [
    "\n",
    "1.It does not tell you how too select a prior .There is no correct way to choose a prior.\n",
    "2.It can produce posterior distributions that rae haevily influenmced by the priors\n",
    "3.It often comes with a high computational cost ,especially in model with a large number of parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e5c00f2",
   "metadata": {},
   "source": [
    "\n",
    "10. Explain how Naïve Bayes classifier is used for\n",
    "\n",
    "1. Text classification\n",
    "\n",
    "2. Spam filtering\n",
    "\n",
    "3. Market sentiment analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d08d2612",
   "metadata": {},
   "source": [
    "NAIVE BAYES FOR TEXT CLASSIFICATION:\n",
    "    there are many different ML algorithm we can choose from when doing text classification with ML. \n",
    "    One familiar of those known as NaiveBayes, Which can provide accurate results without much training data.\n",
    "    In order to leverage the power of bayesain text classification , texts have to be transformed into vectors before classification.\n",
    "    Since a Naive bayes text classification is based on Baysian theorem , Which helps us compute the conditional probabilities of occcurance of two evemts based on the probabilities of occurance of each individual event, encoding those probabilities.\n",
    "    \n",
    "NAIVE BAYES FOR SPAM FILTERS:\n",
    "      Mainly it makes its judgement accoreding to the contents and the title of the email recieved by a user. The system was first set up by a list of potential words usually used by junk email like dealy secret and some then it was further updataed constantly by the users reports of spam emails.\n",
    "      \n",
    " NAIVE BAYES FOR MARKET SENTIMENT ANALYSIS:\n",
    " Naive bayes is simplest algorithm and fastsest classification algorithm for a large  chunk of data In various applications  like sentiment analysis.In market it is used to classify would customer given response is positive or negative ,It automatically done using naive classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc9373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
