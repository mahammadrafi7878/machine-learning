{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6ec7a92a",
   "metadata": {},
   "source": [
    "1. A set of one-dimensional data points is given to you: 5, 10, 15, 20, 25, 30, 35. Assume that k = 2 and that the first set of random centroid is 15, 32, and that the second set is 12, 30.\n",
    "a) Using the k-means method, create two clusters for each set of centroid described above.\n",
    "b) For each set of centroid values, calculate the SSE.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1554318",
   "metadata": {},
   "source": [
    "Given data points : 5, 10, 15, 20, 25, 30, 35\n",
    "and take k value i.e number of centriod are 2, k=2\n",
    "the first set of random centroid is 15,32\n",
    "the second set of random centroid is 12,30\n",
    "\n",
    "In k-means clustering we need to slect data points randomly from given data points, Here k-value is two means we need to slect randomle two points as centroid , In  forst case given data points are 15,32   here 32 is not in dataset so we cannot build clustering , In second case also 12,30  here 12 is out of data point from given dataset so we cannot build groups or cluster on given dataset."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f42ee8f",
   "metadata": {},
   "source": [
    "2. Describe how the Market Basket Research makes use of association analysis concepts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "301d303c",
   "metadata": {},
   "source": [
    "Market basket analysis is a datamining technique used by retailors to increase sales by better understanding customer purchasing patterns.\n",
    "\n",
    "In market basket analysis, association rules are used to predict the likelihood of products being purchased together.\n",
    "Association rules count the frequency of items that occur together , seeking to find associations atht occur far more often them expected.\n",
    "Market basket analysis is a data nining technique used by relatives to increase sales by better understanding customer purchasing patterns.It involves analyzing large datasets ,such as purchase history to reveal product groups as well products that are likely to be pirchased together.\n",
    "There are two types of market basket analysis\n",
    "1.PREDICTIVE MARKET BASKET ANALYSIS:\n",
    "    This type consider items purchased in sequence to determine cross sell\n",
    "    \n",
    "2.DIFFERENTIAL MARKET BASKET ANALYSIS:\n",
    "      This type considers data across different store as well as purchases from different customer groupd during different times of day, month or year.\n",
    "      If a rule holds in one dimension but doesnot hold in the others analysts can determine the factors responsible for the exception .This insights can lead to new product offer that drive higher sales."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d09bf174",
   "metadata": {},
   "source": [
    "3. Give an example of the Apriori algorithm for learning association rules.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93983f99",
   "metadata": {},
   "source": [
    "ASSOCIATION RULE LEARNING: \n",
    "    Association rule learning is a data mining technique which allows us to get interesting insights bof relationship among items.\n",
    "    Association learning rule is simply about finding association between two different things. for example: people who bought bread also bought butter or people who watched 3 idiots also wathe chhichorw movie.\n",
    "    These association rule can be used to find the correlation between distinct items.\n",
    "    \n",
    "APRIORI ALGORITHM:\n",
    "   Apriori algorithm is one of the algorithm used for transaction data in association rule learning.It allows us to mine the frequent item set in order to generate association rule between them.\n",
    "   PRINCIPLES:\n",
    "   1.Subset of frequent itemset are frequent item set.\n",
    "   2.superset of infrequent itemset are infrquent item set.\n",
    "   Apriori algorithm ahs three pars \n",
    "   .SUPPORT\n",
    "   2.CONFIDENCE\n",
    "   3.LIFT \n",
    "   \n",
    " SUPPORT:\n",
    "    support(I) =number of transactions contatining item1 / total number of transactions\n",
    " CONFIDENCE :\n",
    "     confidence(I1>I2)  = number of transactions  caontaining I1 and I2 /number of transactions containing I1\n",
    " LIFT\n",
    "     lift(I1-I2) =confidence(I1>I2)/support I2\n",
    "     \n",
    "ALGORItHM IN NUT SHELL:\n",
    "   10.Set a minimum support and confidence\n",
    "   2.take all subset present in the transctuon , which have higher support than min support\n",
    "   3.Take all the rules of these subsets which have higher confidence than min confidence.\n",
    "   4Sort the rulesby decreasing lift."
   ]
  },
  {
   "cell_type": "raw",
   "id": "028af8ed",
   "metadata": {},
   "source": [
    "4. In hierarchical clustering, how is the distance between clusters measured? Explain how this metric is used to decide when to end the iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bf7107d",
   "metadata": {},
   "source": [
    "Hierarchical clustering involves creating alusters that have a predetermined ordering from top to bottom.\n",
    "For example all files and folders on the hard disk are organized in hierarchy .\n",
    "There are two types of hierarchical clustering DIVISIVE and AGGLOMERATIVE.\n",
    "\n",
    "DIVISIVE:\n",
    "    In divisive or top down clustering method we assign all of the observations to a single cluster then partition the cluster to two least similar clusters using flat clustering method, finally we proceed recursively on each cluster untill there is one cluster for each observation.\n",
    "    \n",
    "AGGLOMERATIVE:\n",
    "     In agglomerative or bottom up clustering method we assign each observation to its own cluster, then n compute similarity between each of the cluster and join the two clusters two most similar clusters . Finally repaet steps 2 and 3 untill there is one single cluster left.\n",
    "     The following three methods differ in how the distance between each cluster is measured.\n",
    "     \n",
    " SINGLE LINKAGE: \n",
    "    In single linkage hierarchical clustering , the distance between two clusters is defined as the shortest distance between two point in each cluster.\n",
    "      L(r,s)= minDIS(Xri-->Xsj)\n",
    "    \n",
    " COMPLETE LINKAGE:\n",
    "     In complete linkage hierachical clustering the distance between two clusters is defined as the longet distance between two points in each cluster.\n",
    "      L(r,s)= maxDIS(Xri-->Xsj)\n",
    "     \n",
    " AVERAGE LINKAGE: \n",
    "   In average linkage hierarchical clustering the distance between two clusters is defined as the averaged distance between each point one cluster to every point in another cluster.\n",
    "    L(r,s)= (1/NrNs)summation (i =1DIS(Xri-->Xsj)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ba35299",
   "metadata": {},
   "source": [
    "5. In the k-means algorithm, how do you recompute the cluster centroids?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c74ea9d2",
   "metadata": {},
   "source": [
    "K-means algorithm find the similarity between to points based on its disatance .The main procedure and steps in  k-means algorithm are ,\n",
    "STEP1:find out centriod Initially taking 'n' number of datapoints randomly and finding their centroids.\n",
    "    Here we are selecting 'k' value randomly , for finding the best value of k we can use ELBOW method.\n",
    "STEP 2:\n",
    "   Calculating euclidean distance between each every point in the datset.which gives less distance then it will belong that centroid.\n",
    "   \n",
    "STEP 3:  After adding a point to cluster we need to update clusters centroid.\n",
    "STEP 4: Iterate untill all the datapoints.\n",
    "\n",
    "\n",
    "In STEP3 we neeed to recompute cluster centriods ,  i.e a data point nearthe cluster centroid then the data point need to be considered as that is belongs to same cluter, Then we need to recomute cetroid as mean or average of that centroid points.\n",
    "  Lets take an example  data set=(8,2,5,7,18,9,15,12,25,20)\n",
    "                          taking random points as c1=6,c2=17\n",
    "                        \n",
    "                        Then we need to calculate distance between first data point with each centriod,\n",
    "                        Then 8 is less distance with c1,The  c1 cluster form as c1=(8,6)  and its centroid will be change as  its mean  (8+6)/2  =7.  \n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "34dcaabf",
   "metadata": {},
   "source": [
    "6. At the start of the clustering exercise, discuss one method for determining the required number of clusters."
   ]
  },
  {
   "cell_type": "raw",
   "id": "df0048c8",
   "metadata": {},
   "source": [
    "In clustering algorithms like k-means clustering , we have to determine right number of clusters for our dataset.\n",
    "\n",
    "ELBOW METHOD:\n",
    "     This method is based on the obseravtion that increasing thr number of clusters can help in reducing the sum of the within cluster variance for each cluster.\n",
    "     Having more clusters allows one to exact finer groups of data objects that are more similar to each other,for choosing the right number of clusters , the training point of the curve of the sum of within cluster variances with respect to the number of clusters is used.\n",
    "     \n",
    "SILHOUETTE SCORE:\n",
    "      Silhouette score is used to evaluate the quality od clusters created using clustering algorithm such as k -means in terms of how well the data points are clusterd with other data point that are similar to each other.\n",
    "      This method can be used to find the optimal value of 'k' hqaving within the range of [-1,1].\n",
    "      The value of 'k' having the silhouette score nearer to 1 can be considered as the right number of clusters \n",
    "      \n",
    "      formula =  b-a/max(b,a)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f9af0dd",
   "metadata": {},
   "source": [
    "7. Discuss the k-means algorithm's advantages and disadvantages.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74a6e308",
   "metadata": {},
   "source": [
    "ADVANTAGES:\n",
    "    1.Scales to large datasets.\n",
    "    2.Can warm start the position of centroids.\n",
    "    3.Easily adopts to new examples.\n",
    "    4.Generalizes to clusters of different shapes and sizes such as eliptical clusters.\n",
    "    5.Guarantee convergence\n",
    "    6.Relatively simple to implement.\n",
    "    \n",
    "    \n",
    "DISADVANTAGES:\n",
    "1.Choosing k manually.\n",
    "2.Being independent on initial values.\n",
    "3.Clustering data of variying sizes density.\n",
    "4.Clustering outliers.\n",
    "5.Scaling with number of dimensions.\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f2f8211",
   "metadata": {},
   "source": [
    "8. Draw a diagram to demonstrate the principle of clustering."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2016b59f",
   "metadata": {},
   "source": [
    "It is basically a type of unsupervised learning method. clustering is the task of dividing the population or data points into a number of groups such that data points 'n' the same groups are more similar to other data points in the same group and disimilar to the data points in other groups .It is basically  a collection of objects on the basis of similarity and dis similarity between them"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da072a47",
   "metadata": {},
   "source": [
    "9. During your study, you discovered seven findings, which are listed in the data points below. Using the K-means algorithm, you want to build three clusters from these observations. The clusters C1, C2, and C3 have the following findings after the first iteration:\n",
    "\n",
    "C1: (2,2), (4,4), (6,6); C2: (2,2), (4,4), (6,6); C3: (2,2), (4,4),\n",
    "\n",
    "C2: (0,4), (4,0), (0,4), (0,4), (0,4), (0,4), (0,4), (0,4), (0,\n",
    "\n",
    "C3: (5,5) and (9,9)\n",
    "\n",
    "What would the cluster centroids be if you were to run a second iteration? What would this clustering's SSE be?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fa75d91",
   "metadata": {},
   "source": [
    "finding centroid for data point in cluster C is \n",
    "     C1=((2+4+6)/3),((2+4+6)/3)) =4,4\n",
    "finding centriod for data points in cluster C2 is \n",
    "    C2=((0+4)/2,(0+4)/2)= 7,7\n",
    "finding centroid for datapoints in cluster C3 is\n",
    "   C3=((5+9)/2,(5+9)/2)=7,7\n",
    "   \n",
    "   the first cluster C1  SSE will be  8\n",
    "    the first cluster C2  SSE will be  8\n",
    "     the first cluster C3  SSE will be  8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65466269",
   "metadata": {},
   "source": [
    "10. In a software project, the team is attempting to determine if software flaws discovered during testing are identical. Based on the text analytics of the defect details, they decided to build 5 clusters of related defects. Any new defect formed after the 5 clusters of defects have been identified must be listed as one of the forms identified by clustering. A simple diagram can be used to explain this process. Assume you have 20 defect data points that are clustered into 5 clusters and you used the k-means algorithm."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e105993",
   "metadata": {},
   "source": [
    "Here we have 20 defect datapoints.\n",
    "based on text analytics of defect details they decide to bild 5 cluster of related defects.\n",
    "So here k-value is 5  , we need create five clusters and identify first 5 different types of defects .\n",
    "Lets selecting 5 differnt defects are in 20 defects ,suppose   d7,d3,d11,d15 and d18 are five different flaws .\n",
    "\n",
    "Based on related defects of software testing , which remain data defect points are related one of the above 5 cluster points they will grouped together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
