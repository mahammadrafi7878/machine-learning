{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1015ed32",
   "metadata": {},
   "source": [
    "1. What is the definition of a target function? In the sense of a real-life example, express the target function. How is a target function's fitness assessed?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "476d6d21",
   "metadata": {},
   "source": [
    "The target function is essentially the formula that an algorithm feeds data inorder to calculate predictions.As in algebra it is common when training AI to find the variable from the solution , working in reverse. The function defined by 'f' is applied to the input '1' to produce output '0' thyen  0=f(1).\n",
    "A target function in ML is a method for solving a problem that an AI also parses its training data to find once an algorithm finds itxs target function that function can be used to predict results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc920ce0",
   "metadata": {},
   "source": [
    "2. What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c1226d6",
   "metadata": {},
   "source": [
    "Predictive modeling is a commonly used atatistical technique to predict future behaviour .\n",
    "Predictive modeling solutions are a form of data mining technology, That works by analyzing historical and current data and generating a model to help predict future outcomes.\n",
    "        The supervised laerning algorithms is a subset of the family of ML algorithms which are mainly used in predictive modeling.\n",
    "      A predictive model is basically a model constructed from ML algorithms and features or attributes from training data such that we can predict a value using the other values obtained from the input data.\n",
    "      Supervised algorithms try to model relationships and dependencies betrween the target prediction output and the input feature  such that we can predict the output values for new data based on those relationships which it learned from previous datatypes.\n",
    "       e.g classification and regression\n",
    "       \n",
    "       \n",
    "       \n",
    "   The unsupervised learning algorithms are the family of machine learning algorithms which are mainly usedf in pattern detection and descriptive modeling. How ever there are no output categories or labels here based on which the algorithm can try to model relation ships.These algorithms try to use techniques on the input data to mine rule s -detect patterns and summerize and group the data points.\n",
    "   WWhich help in deriving meaningful insights and describe the data better to the users.\n",
    "   e.g cluster and association learning.a desriptive model will explot the past data that are stored in databases and provide you with the accurate report.\n",
    "         In a predictive model , it identifies patterns found in past and transactional daqta to find risk and future outcomes. Descriptive analysis will gives a vision into the past and tells you, what has happened , where as the predictive analytics will recognize the futur and tell you what might happen in future.\n",
    "         \n",
    "      "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc180d22",
   "metadata": {},
   "source": [
    "3. Describe the method of assessing a classification model's efficiency in detail. Describe the various measurement parameters."
   ]
  },
  {
   "cell_type": "raw",
   "id": "16105adb",
   "metadata": {},
   "source": [
    "         After building a model we need to test model how accurate or how generalize our model is.This method is called as method of assessing classification model efficiency .\n",
    "         There are eieght metrices for classification performance..\n",
    "      Classification is a type of suprvised ML problem where the goal is to predict for one or more observations , the category or classs they belong to , \n",
    "      This is the process where we use the trained model to make predictions  on previously unseen labelled data , In the case of classification , we then evaluate how many  of these predictions are model got right.\n",
    "      \n",
    "      some various measurement parameters are Accuracy,Precision,Recall , F1score , kappa Scre and MCC."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c53ce73b",
   "metadata": {},
   "source": [
    "4. \n",
    "i. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?\n",
    "ii. What does it mean to overfit? When is it going to happen?\n",
    "iii. In the sense of model fitting, explain the bias-variance trade-off.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf9007fe",
   "metadata": {},
   "source": [
    "i. In the sense of machine learning models, what is underfitting? What is the most common reason for underfitting?\n",
    "\n",
    "Your model is underfitting the training data , when the model perfoms poorly on the traing data .This is because of the model is unable to captoure the relation ship between the input and output features."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3267eb1",
   "metadata": {},
   "source": [
    " What does it mean to overfit? When is it going to happen?:\n",
    "        your model is overfitting you are training data  where you see that the model performs well on the training data but doesnot perform well on the evaluation data , this is because the model is memorizing the data it has seen and unable to generalize to unseen examples."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d62f358",
   "metadata": {},
   "source": [
    "In the sense of model fitting, explain the bias-variance trade-off.\n",
    "       \n",
    "       In statistics and machine learning the bias variance trade off is the property of a model that the variance tradeoff is the property of model that the variance of parameter estimated across samples can be reduced by increasing the bias in the essential parameters.\n",
    "          Biaqs variance trade off is the conflict in trying to symultaneously minimize these two sources of error that prevent supervised learning algorithm from generalzing beyond their training set.\n",
    "          The bias error is an error from errorenous assumption in the learning algorithm.High bias can cause an algorithm to miss the relevent relations between features and target outputs.\n",
    "          The variance is an error from sensitivity to small fluctuations in the training set. High variance may result from an algorithm modeling the random noise in the training data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "343695aa",
   "metadata": {},
   "source": [
    "5. Is it possible to boost the efficiency of a learning model? If so, please clarify how."
   ]
  },
  {
   "cell_type": "raw",
   "id": "14aacf1f",
   "metadata": {},
   "source": [
    "Yes, it is possible to boost the efficiency of a learning model .There are various methods you can improve laerning model performance.\n",
    "five ways to improve performance of ML models: \n",
    "1.choosing the right algorithm.\n",
    "     Algorithms are the key factor used to train ML model. The data feed into this that helps the model to learn from and predict with accurate results ,since choosing the right algorithm is important to ensure the performance of your ML model.\n",
    "     \n",
    "2.Use the right Quality of data.\n",
    "    The next important factor you can consider while developing a ML model is choosing the right quantity of datasets and there are multi role factor for ML models.\n",
    "    \n",
    "3.Quality of training data.\n",
    "    Just like quauntity , The quality of ML training data set is another key factor .If the quality of ML dataset is not good or accurate you model will nwver give aqccurate results.\n",
    "    \n",
    "4.Selectin supaervised or unsupercised models.\n",
    "5.Model validation and testing:\n",
    "  Building a model is not enough to getthe right predictions as you have to check the accuracy and need to validate the same to ensure get the precise results and validating the model will improve the performance of the ML model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebf36a90",
   "metadata": {},
   "source": [
    "6. How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b32abd3",
   "metadata": {},
   "source": [
    "Clustering is the most common form of unsupervised learning , we dont have any labels in clustering , we have just a sert of features or observations and your goal is to create cluster that have similar observations kept as for as possible.\n",
    "Evaluation the performance of clustering algorithm is not as trival as counting the number error or the precision and recall like in the case of SL.\n",
    "Hence cluster are evaluated based on some similarities or disimilarity measure such as distance between cluster points.\n",
    "If the clustering algorithm seperates disimilar observations apart and similar observations together, then it has performed welll , two most popular metrices evaluation metric for clustering algorithm are \n",
    "1.silhouette score 2.Dunn index.\n",
    "\n",
    "SILHOUETTE SCORE:\n",
    "silhoette coefficient or silhouette swcore is a metric use to calculate the goodness of a clustering technique its values range from -1to 1.\n",
    "       1 means clusters are well apart from each other and clearly distinguished.\n",
    "       0 means clusters are in different or we can say that the distance between  cluster is not significant.\n",
    "       -1 means clusters are assigned in wrong way \n",
    "       \n",
    "     silhoette score formula is given as \n",
    "     \n",
    "        silhouette score=b-a/(max(a,b))\n",
    "      \n",
    "      where 'a' average intra cluster distance(average distance between each point within a cluster\n",
    "            'b' average inter cluster distance i.e the average distance between all clusters.\n",
    "      \n",
    " DUNN INDEX:\n",
    "     Dunn index formula is given as  \n",
    "          \n",
    "             dunn index= max dist(xi,xj)/ max dist(yi,yj)\n",
    "            \n",
    "            \n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "id": "cefc89fb",
   "metadata": {},
   "source": [
    "7. Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b869e4e",
   "metadata": {},
   "source": [
    "Yes it is possible , we can use classification model for numerical data , where as the target column has  numerical data is disrete in nature i.e not continuous values.If we have input features as numeric and target feature is classes or numerical value with discrete in nature , with limited number of classes or we can use feature binning we can use claasification model for numerical data.\n",
    "\n",
    "We cannot use regression model for categorical data which target column has. If we have input feauters as categorical and target feature is continuous in this cases we can use regression model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8312d4d",
   "metadata": {},
   "source": [
    "8. Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26512afc",
   "metadata": {},
   "source": [
    "Regression algorithms are ML techniques for predicting continuous numerical value.They are supervised learning tasks which mean they required labeled training examples\n",
    "\n",
    "USE CASE:  predicting the appropriate price forn a product based upon size , brand, location predicting the number of sales per each day based upon store , location and public holidays \n",
    "\n",
    " Categorical contains only class this are not continuous in nature ."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3699fc2c",
   "metadata": {},
   "source": [
    "9. The following data were collected when using a classification model to predict the malignancy of a group of patients' tumors:\n",
    "i. Accurate estimates – 15 cancerous, 75 benign\n",
    "ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8d62ef9",
   "metadata": {},
   "source": [
    "From above problem we can get information using confusion matrix \n",
    "\n",
    "                                 actual value\n",
    "                             cancerous      bengin\n",
    "                  cancerous   15              3\n",
    "   \n",
    "   predicted value  bengin     7               75   \n",
    "   \n",
    "   \n",
    "   \n",
    "   from the above confusion matrix we can see True Positive(TP)=  15\n",
    "                                              False Positive (FP)= 7\n",
    "                                              False Negative (FN)= 3\n",
    "                                              True Negative (TN)=75\n",
    "                                              \n",
    "           Error rate formula is given as  =TP+TN/(TP+FP+FN+TN)   =15+75/(15+75+3+7)  =90/100 =0.9\n",
    "           \n",
    "           Kappa Value formula is given as =Agree - chance of Agree/(1 - chance of Agree)\n",
    "           \n",
    "           Agree = sum of diagonal elemets divide by total number of elements =90/100=0.9\n",
    "           \n",
    "            chance of agree=probability cancerous+probability of bengin\n",
    "            \n",
    "            \n",
    "            actual probability(cancerous)=22/100    =0.22\n",
    "            predicted probability(cancerous)=  18/100 =0.18\n",
    "            \n",
    "            predicted probability of (bengin)=82/100=0.88\n",
    "            actual probability (bengin)=78/100=0.78\n",
    "            \n",
    "            chance of agree value=0.039 \n",
    "            \n",
    "            kappa value=  0.9-0.675/(0.575)= 0.3918\n",
    "            \n",
    "            kappa value less than 0.4 consider qas poor kappa value.\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "     SENSITIVITY:\n",
    "             Recall is also called as sensitivity , the formula for Recall is given as \n",
    "                   Recall or Sensitivity = TP/(TP+FN)\n",
    "                                         =15/(15+3)\n",
    "                                         =0.833\n",
    "    \n",
    "    \n",
    "    \n",
    "    PRECISION :\n",
    "        Precision formua is given as  \n",
    "               Precision=TP/(TP=FP)\n",
    "                         =15/(15+7)\n",
    "                         =0.68\n",
    "     F1-MEASURE:\n",
    "         F1 -measure formula is given as \n",
    "                 F1-measure= 2PR/P+R\n",
    "                           =2*0.83*0.68/(0.83+0.68)\n",
    "                           =0.74\n",
    "     \n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ece8cc8a",
   "metadata": {},
   "source": [
    "10. Make quick notes on:\n",
    "1. The process of holding out\n",
    "2. Cross-validation by tenfold\n",
    "3. Adjusting the parameters\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7a082e9",
   "metadata": {},
   "source": [
    "The process of holding out\n",
    "    The hold out method for training a machine learning model is the process of splitting the data into different split for training the model and other splits for validating and testing the models.Instead of using entire adatset for for training , dividing adata set into traing,testind and validation purpose.\n",
    "    The validation setr and test set are seperate or set a side is called as the hold out.\n",
    "    \n",
    "    \n",
    "Cross-validation by tenfold:\n",
    "    With this dataset we have one dataset which we divide randomly into 10 parts.We use 9 out of those parts for training and reverse one tenth for testing. We repeat this procedure10 times each time reversing a different tenth for testing. claculate accuracy each time. and which k value gives maximum accuracy we can taken that value as k value.\n",
    "    \n",
    " Adjusting the parameters:\n",
    "      In Ml or DL a model is defined or represented by the model parameters , However the process of training a model involues choosing the otimal parameters or hyperparameters that the learning algorithm will use to learn the optimal parameters that correctly map the input feature to the labes ."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3b9f794",
   "metadata": {},
   "source": [
    "11. Define the following terms: \n",
    "1. Purity vs. Silhouette width\n",
    "2. Boosting vs. Bagging\n",
    "3. The eager learner vs. the lazy learner\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dafb25a",
   "metadata": {},
   "source": [
    "Purity vs. Silhouette width:\n",
    "    Purity and silhoette score both are used as evaluation metrics for clustering problems.\n",
    "    Here purity is nothing but the maximum number of correctly classifid points in a cluster.\n",
    "         Purity =max(P)\n",
    "     silhoette coefficient or silhouette swcore is a metric use to calculate the goodness of a clustering technique its values range from -1to 1.\n",
    "       1 means clusters are well apart from each other and clearly distinguished.\n",
    "       0 means clusters are in different or we can say that the distance between  cluster is not significant.\n",
    "       -1 means clusters are assigned in wrong way \n",
    "       \n",
    "     silhoette score formula is given as \n",
    "     \n",
    "        silhouette score=b-a/(max(a,b))\n",
    "      \n",
    "      where 'a' average intra cluster distance(average distance between each point within a cluster)(\n",
    "            'b' average inter cluster distance i.e the average distance between all clusters.\n",
    "         \n",
    "         \n",
    "  Boosting vs. Bagging: \n",
    "      Boosting and Bagging these are one of ensemble techniques.\n",
    "      In Bagging we take sample dataset from population dataset .There is a specific algorithm in bagging technique is called as Random Forest. When we have low bias and high variance model we can use bagging technique to reduce variance without harming bias of the model.\n",
    "      \n",
    "      When a model have low variance or high variance and high bias model , we can use boosting techinique to reduce high bias. In boosting we have weak classifier ,we pass information sequentially to the models.\n",
    "      \n",
    "      The eager learner vs. the lazy learner:\n",
    "             the model which perform based on some mathematical formulas or functions is known as eager learner.It stores functions as a model For example : logistic regression.\n",
    "             IF a model does not follow functions or mathematical formulas then it is called as the lazy learners .It store all the dataset as model .Example: KNN model , It is worked based on disatance method.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64af5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
